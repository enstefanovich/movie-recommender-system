{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data needed to make the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movies_preprocessed_unstandardized.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m movie_features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovies_preprocessed_unstandardized.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m reviews200 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_reviews_200moviesplus.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m movie_titles \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_movies_id_appended.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_title\u001b[39m\u001b[38;5;124m'\u001b[39m], index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movies_preprocessed_unstandardized.csv'"
     ]
    }
   ],
   "source": [
    "movie_features = pd.read_csv('movies_preprocessed.csv', index_col='movieId')\n",
    "reviews200 = pd.read_csv('user_reviews_200moviesplus.csv')\n",
    "movie_titles = pd.read_csv('clean_movies_id_appended.csv', usecols=['movieId', 'original_title'], index_col='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to make a matrix where every row is a user and every column is a movie. Then replacing null values for unseen movies with 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_review_matrix(user_reviews, user_id):\n",
    "    review_matrix = user_reviews.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    if user_id not in review_matrix.index:\n",
    "        raise ValueError(\"User ID not found in review matrix\")\n",
    "\n",
    "    return review_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the user-review matrix using only users with over 200 movies reviewed. Originally I wanted to use a larger sample, but decided to scale down the size of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_matrix = create_user_review_matrix(reviews200, 3)\n",
    "\n",
    "movie_features = movie_features[movie_features.index.isin(user_review_matrix.columns)]  #Filtering out movies that are not in the user reviews\n",
    "movie_titles = movie_titles[movie_titles.index.isin(user_review_matrix.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I wanted to find the most similar users to a given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will return the k-nearest users to a given user, based on cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(review_matrix, user_vector, k=25):\n",
    "    knn = NearestNeighbors(n_neighbors=k + 1, metric='cosine', n_jobs=-1)\n",
    "    knn.fit(review_matrix)\n",
    "    distances, indices = knn.kneighbors(user_vector, n_neighbors=k + 1)\n",
    "    nearest_neighbors = [review_matrix.index[indices[0, j]] for j in range(1, k + 1)]\n",
    "    neighbor_distances = distances[0,1:k+1]\n",
    "    return nearest_neighbors , neighbor_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing this function on a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "user = user_review_matrix.loc[3].to_numpy().reshape(1,-1)\n",
    "\n",
    "neighbors, distances = find_similar_users(user_review_matrix, user)\n",
    "print(neighbors)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I needed to create a way to get a user's predicted rating for a given movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_predict_ratings(movie_id, review_matrix, neighbors, distances):\n",
    "\n",
    "    if movie_id not in review_matrix.columns:\n",
    "        return np.nan\n",
    "    \n",
    "    # Get indices of neighbors who have rated this movie\n",
    "    valid_indices = [i for i, neighbor in enumerate(neighbors) if review_matrix.loc[neighbor, movie_id] > 0]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        return np.nan\n",
    "    \n",
    "    # Getting ratings and distances for valid neighbors\n",
    "    ratings = np.array([review_matrix.loc[neighbors[i], movie_id] for i in valid_indices])\n",
    "    valid_distances = distances[valid_indices]\n",
    "    \n",
    "    # Convert distances to weights (smaller distance = larger weight)\n",
    "    # Add small constant to avoid division by zero\n",
    "    weights = 1 / (valid_distances ** 2 + 0.001)\n",
    "    \n",
    "    # Calculate weighted average\n",
    "    weighted_avg = np.sum(ratings * weights) / np.sum(weights)\n",
    "    \n",
    "    return weighted_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing this on the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rating = weighted_predict_ratings(1,user_review_matrix, neighbors, distances)\n",
    "print(predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also wanted to create a way to find similar movies, which is accomplished with this function. It finds the most similar neighbors to a given movie based on the vector of its attributes. It returns the movie ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies(movie_vector, movies_df, movies_titles, num_recommendations=5):\n",
    "    knn = NearestNeighbors(n_neighbors=num_recommendations + 1, metric='cosine', n_jobs=-1)\n",
    "    knn.fit(movies_df)\n",
    "    distances, indices = knn.kneighbors(movie_vector, n_neighbors=num_recommendations + 1)\n",
    "    similar_movies = movies_titles.iloc[indices[0][1:]].index.tolist()\n",
    "    \n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing this on movie ID one, which is Toy Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_story = movie_features.loc[1].to_numpy().reshape(1,-1)\n",
    "\n",
    "similar_ids = find_similar_movies(toy_story, movie_features, movie_titles, 5)\n",
    "\n",
    "for i in similar_ids:\n",
    "    print(movie_titles.loc[i]['original_title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I needed to create a version of the recommender that allows me to test predicted ratings against actual ratings of new users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recommend(user_reviews, movies_df, movie_titles, review_matrix, user_id, test_users_matrix):\n",
    "\n",
    "    predicted_ratings = []      #Empty lists to store predicted and true ratings\n",
    "    true_ratings = []\n",
    "\n",
    "    reviewed_movies = user_reviews.loc[user_reviews > 0]    #Finding the movies that the user has seen\n",
    "    reviewed_movies = reviewed_movies.index\n",
    "\n",
    "    favorite_movies = user_reviews[user_reviews >= 4]   #Finding the movies that the user has rated over 4. This is so we only find movies similar to movies they liked\n",
    "    valid_favorite_movies = favorite_movies[favorite_movies.index.isin(user_review_matrix.columns)]     #Making sure movies are present in the user-review matrix\n",
    "\n",
    "    if len(valid_favorite_movies) == 0:  \n",
    "        return None, None\n",
    "    \n",
    "    movie_vectors = movies_df.loc[favorite_movies.index]    #These are the vectors of all the users liked movies\n",
    "\n",
    "    composite_vector = movie_vectors.mean(axis=0)   #This vector is the average value of all the features of the users liked movies\n",
    "    composite_vector = composite_vector.values.reshape(1,-1)\n",
    "    \n",
    "    user_ratings = user_reviews.to_frame().T    \n",
    "    \n",
    "    similar_users, user_distances = find_similar_users(review_matrix, user_ratings)     #Here I am finding the most similar users to the given user\n",
    "    similar_movies = find_similar_movies(composite_vector, movies_df, movie_titles, 10)    #Here I am finding the 10 most similar movies to the average favorite movie vector\n",
    "\n",
    "    similar_movies = [movie for movie in similar_movies if movie not in reviewed_movies]    #Excluding movies that we have a rating for already\n",
    "\n",
    "    for movie in similar_movies:\n",
    "        \n",
    "        rating = weighted_predict_ratings(movie, review_matrix, similar_users, user_distances)\n",
    "        \n",
    "        if pd.isna(rating):\n",
    "            rating = user_review_matrix[user_review_matrix[movie]>0][movie].mean()\n",
    "\n",
    "        if test_users_matrix.loc[user_id, movie] > 0:   #If the test user has actually reviewed the movie append the rating and predicted rating\n",
    "\n",
    "            true_ratings.append(test_users_matrix.loc[user_id, movie])      \n",
    "            predicted_ratings.append(rating)\n",
    "        \n",
    "    return true_ratings, predicted_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the recommender, I created several test groups of users from the large original review dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sample sets contain users with 10, 20, 50, and 100 reviews of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_10 = pd.read_csv('user_reviews_10_reviews.csv')\n",
    "reviews_test_20 = pd.read_csv('user_reviews_20_reviews.csv')\n",
    "reviews_test_50 = pd.read_csv('user_reviews_50_reviews.csv')\n",
    "reviews_test_100 = pd.read_csv('user_reviews_100_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating matrices out of these data samples, reindexing to account for movies missing from these reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_matrix_10 = create_user_review_matrix(reviews_test_10, 182).reindex(columns=user_review_matrix.columns, fill_value=0)\n",
    "test_users_matrix_20 = create_user_review_matrix(reviews_test_20, 24).reindex(columns=user_review_matrix.columns, fill_value=0)\n",
    "test_users_matrix_50 = create_user_review_matrix(reviews_test_50, 99).reindex(columns=user_review_matrix.columns, fill_value=0)\n",
    "test_users_matrix_100 = create_user_review_matrix(reviews_test_100, 8).reindex(columns=user_review_matrix.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed to create a function to split the user-review matrices into training and testing segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def train_test_split_user(user_ratings, test_ratio= 0.2):\n",
    "\n",
    "    reviewed_movies = user_ratings[user_ratings > 0].index.tolist()\n",
    "\n",
    "    test_movies = sample(reviewed_movies, max(1, int(len(reviewed_movies) * test_ratio)))   \n",
    "\n",
    "    train_ratings = user_ratings.copy()\n",
    "    test_ratings = user_ratings.copy()\n",
    "\n",
    "    train_ratings[test_movies] = 0\n",
    "\n",
    "    test_ratings[~test_ratings.index.isin(test_movies)] = 0\n",
    "\n",
    "    train_ratings = train_ratings.to_numpy().reshape(1,-1)\n",
    "    test_ratings = test_ratings.to_numpy().reshape(1,-1)\n",
    "\n",
    "    return train_ratings, test_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also needed a way to test the RMSE on the tested samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm   #This enables a progress bar, not necessary, but this can take a while to run\n",
    "\n",
    "def testing_rmse(test_users_matrix):\n",
    "    true_ratings___ = []\n",
    "    predicted_ratings___ = []\n",
    "    user_ids = []\n",
    "\n",
    "    for i in tqdm(test_users_matrix.index, desc=\"Testing RMSE\", unit=\"user\"):\n",
    "\n",
    "        train_user, test_user = train_test_split_user(test_users_matrix.loc[i])     #Splitting the users reviews so we have some movies to predict\n",
    "        train_user = np.array(train_user[0])\n",
    "        train_user = pd.Series(train_user, index=test_users_matrix.loc[i].index)\n",
    "\n",
    "        tr, pr = test_recommend(train_user, movie_features, movie_titles, user_review_matrix, i, test_users_matrix)\n",
    "        \n",
    "        if tr == None:\n",
    "            continue\n",
    "\n",
    "        for j in range(len(tr)):\n",
    "            true_ratings___.append(tr[j])\n",
    "            predicted_ratings___.append(pr[j])\n",
    "            user_ids.append(i)\n",
    "    \n",
    "    return true_ratings___, predicted_ratings___, user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the RMSE on users with 10 movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the RMSE and MAE found on movies that would be recommended to the user, that they have already reviewed, but were excluded from the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)    #Suppressing this warning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
    "\n",
    "tr, pr, uid = testing_rmse(test_users_matrix_10)\n",
    "\n",
    "rmse = root_mean_squared_error(tr, pr)\n",
    "mae = mean_absolute_error(tr, pr)\n",
    "print(f'RMSE for 10 review users: {rmse}')\n",
    "print(f'MAE for 10 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the true ratings and the predicted rating when using the movies average rating as the prediction. This is to compare versus our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_rating(user_review_matrix):\n",
    "    mean_ratings = {}\n",
    "    \n",
    "    for i in tqdm(user_review_matrix.columns, desc=\"Calculating mean ratings\", unit=\"movie\"):\n",
    "        movie_mean_rating = user_review_matrix[user_review_matrix[i] > 0][i].mean()\n",
    "        mean_ratings[i] = movie_mean_rating\n",
    "    \n",
    "    return mean_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = mean_rating(user_review_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the mean rating to the reviews dataframe and finding the RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_10['mean_rating'] = reviews_test_10['movieId'].map(mean_ratings)\n",
    "reviews_test_10['mean_rating'] = reviews_test_10['mean_rating'].fillna(0)\n",
    "\n",
    "rmse = root_mean_squared_error(reviews_test_10['rating'], reviews_test_10['mean_rating'])\n",
    "mae = mean_absolute_error(reviews_test_10['rating'], reviews_test_10['mean_rating'])\n",
    "print(f'RMSE for 10 review users: {rmse}')\n",
    "print(f'MAE for 10 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE obtained from our models predictions is an improvement over the baseline of avg. movie rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the RMSE on users with 20 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_20, pr_20, uid_20 = testing_rmse(test_users_matrix_20)\n",
    "\n",
    "rmse = root_mean_squared_error(tr_20, pr_20)\n",
    "mae = mean_absolute_error(tr_20, pr_20)\n",
    "print(f'RMSE for 20 review users: {rmse}')\n",
    "print(f'MAE for 20 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the baseline of average movie rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_20['mean_rating'] = reviews_test_20['movieId'].map(mean_ratings)\n",
    "reviews_test_20['mean_rating'] = reviews_test_20['mean_rating'].fillna(0)\n",
    "\n",
    "rmse = root_mean_squared_error(reviews_test_20['rating'], reviews_test_20['mean_rating'])\n",
    "mae = mean_absolute_error(reviews_test_20['rating'], reviews_test_20['mean_rating'])\n",
    "print(f'RMSE for 20 review users: {rmse}')\n",
    "print(f'MAE for 20 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the RMSE on users with 50 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_50, pr_50, uid_50 = testing_rmse(test_users_matrix_50)\n",
    "\n",
    "rmse = root_mean_squared_error(tr_50, pr_50)\n",
    "mae = mean_absolute_error(tr_50, pr_50)\n",
    "print(f'RMSE for 50 review users: {rmse}')\n",
    "print(f'MAE for 50 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the baseline of average movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_50['mean_rating'] = reviews_test_50['movieId'].map(mean_ratings)\n",
    "reviews_test_50['mean_rating'] = reviews_test_50['mean_rating'].fillna(0)\n",
    "\n",
    "rmse = root_mean_squared_error(reviews_test_50['rating'], reviews_test_50['mean_rating'])\n",
    "mae = mean_absolute_error(reviews_test_50['rating'], reviews_test_50['mean_rating'])\n",
    "print(f'RMSE for 50 review users: {rmse}')\n",
    "print(f'MAE for 50 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the RMSE on users with 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_100, pr_100, uid_100 = testing_rmse(test_users_matrix_100)\n",
    "\n",
    "rmse = root_mean_squared_error(tr_100, pr_100)\n",
    "mae = mean_absolute_error(tr_100, pr_100)\n",
    "print(f'RMSE for 100 review users: {rmse}')\n",
    "print(f'MAE for 100 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the baseline of average movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_100['mean_rating'] = reviews_test_100['movieId'].map(mean_ratings)\n",
    "reviews_test_100['mean_rating'] = reviews_test_100['mean_rating'].fillna(0)\n",
    "\n",
    "rmse = root_mean_squared_error(reviews_test_100['rating'], reviews_test_100['mean_rating'])\n",
    "mae = mean_absolute_error(reviews_test_100['rating'], reviews_test_100['mean_rating'])\n",
    "print(f'RMSE for 20 review users: {rmse}')\n",
    "print(f'MAE for 20 review users: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running these tests multiple times, we can see that the model consistently out-performs the baseline. Also, the RMSE decreases as the user reviews more movies, which is as expected! There is a point of diminishing returns when a user has reviewed ~50 movies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
